import asyncio
from autogen_ext.models.openai import OpenAIChatCompletionClient
from autogen_agentchat.teams import MagenticOneGroupChat
from autogen_agentchat.ui import Console
from autogen_ext.agents.web_surfer import MultimodalWebSurfer
from autogen_ext.agents.file_surfer import FileSurfer
from autogen_ext.agents.magentic_one import MagenticOneCoderAgent
from autogen_agentchat.agents import CodeExecutorAgent
from autogen_ext.code_executors.local import LocalCommandLineCodeExecutor
from typing import Any, Dict, List, Literal, Optional, Union, Tuple, Callable
import random
import json
import argparse
import os


def load(force_download=False):
        r"""Load the GAIA dataset.

        Args:
            force_download (bool, optional): Whether to
                force download the data.
        """
        # Define validation and test directories - use relative paths or environment variables
        valid_dir = os.getenv("GAIA_VALIDATION_DIR", "./data/gaia/2023/validation")
        test_dir = os.getenv("GAIA_TEST_DIR", "./data/gaia/2023/test")

        all_data = {}
        # Load metadata for both validation and test datasets
        for path, label in zip([valid_dir, test_dir], ["valid", "test"]):
            all_data[label] = []
            with open(f"{path}/metadata.jsonl", "r") as f:
                lines = f.readlines()
                for line in lines:
                    data = json.loads(line)
                    if data["task_id"] == "0-0-0-0-0":
                        continue
                    if data["file_name"]:
                        data["file_name"] = f"{path}/{data['file_name']}"
                    all_data[label].append(data)
        return all_data

def load_tasks(
        on: Literal["valid", "test"],
        level: Union[int, List[int], Literal["all"]],
        randomize: bool = False,
        subset: Optional[int] = None,
        idx: Optional[List[int]] = None,
        use_subset: bool = False,
        subset_file: Optional[str] = None,
    ) -> List[Dict[str, Any]]:
        r"""Load tasks from the dataset."""
        gaia_data = load()
        if on not in ["valid", "test"]:
            raise ValueError(
                f"Invalid value for `on`: {on}, expected 'valid' or 'test'."
            )
        levels = (
            [1, 2, 3]
            if level == "all"
            else [level]
            if isinstance(level, int)
            else level
        )   
        
        datas = [data for data in gaia_data[on] if data["Level"] in levels]
        
        # å¦‚æœä½¿ç”¨å­é›†ï¼Œè¿‡æ»¤ä»»åŠ¡
        if use_subset and subset_file:
            if os.path.exists(subset_file):
                with open(subset_file, 'r', encoding='utf-8') as f:
                    subset_data = json.load(f)
                    subset_task_ids = set(subset_data.get("task_ids", []))
                    print(f"ğŸ“‹ ä½¿ç”¨å­é›†æ•°æ®é›†: {subset_file}")
                    print(f"ğŸ“Š å­é›†åŒ…å« {len(subset_task_ids)} ä¸ªä»»åŠ¡")
                    
                    # è¿‡æ»¤æ•°æ®
                    original_count = len(datas)
                    datas = [data for data in datas if data["task_id"] in subset_task_ids]
                    print(f"ğŸ” è¿‡æ»¤åå‰©ä½™ {len(datas)} ä¸ªä»»åŠ¡ (ä» {original_count} ä¸ª)")
            else:
                print(f"âš ï¸  å­é›†æ–‡ä»¶ä¸å­˜åœ¨: {subset_file}")
        
        if randomize:
            random.shuffle(datas)
        if subset:
            datas = datas[:subset]
        
        if idx is not None:
            # pick only the tasks with the specified idx
            if len(idx) != 0:   
                datas = [datas[i] for i in idx]
                
        return datas

async def run_task_and_capture_log(team, task_prompt):
    # æ•è· Console çš„è¾“å‡º
    from io import StringIO
    import sys

    old_stdout = sys.stdout
    sys.stdout = mystdout = StringIO()
    try:
        print(f"Running task: {task_prompt}")
        await Console(team.run_stream(task=task_prompt))
    finally:
        sys.stdout = old_stdout
    return mystdout.getvalue()

async def main() -> None:
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description="GAIA æµ‹è¯•è„šæœ¬")
    parser.add_argument("--level", type=int, default=2, help="GAIA level (1, 2, 3)")
    parser.add_argument("--on", type=str, default="valid", choices=["valid", "test"], help="æ•°æ®é›†ç±»å‹")
    parser.add_argument("--use-subset", action="store_true", help="ä½¿ç”¨å­é›†æ•°æ®é›†")
    parser.add_argument("--subset-file", type=str, default="owl/data/gaia_subset.json", help="å­é›†æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--subset-size", type=int, help="é™åˆ¶å­é›†å¤§å°")
    parser.add_argument("--randomize", action="store_true", help="éšæœºåŒ–ä»»åŠ¡é¡ºåº")
    
    args = parser.parse_args()

    # åˆ›å»ºç‹¬ç«‹çš„ model clients é¿å…å…±äº«
    def create_model_client():
        return OpenAIChatCompletionClient(
            model="gpt-4o-mini-2024-07-18",
            api_key=os.getenv("OPENAI_API_KEY", "YOUR_OPENAI_API_KEY_HERE"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.openai.com/v1")
        )
    
    LEVEL = args.level
    on = args.on
    if args.use_subset:
        OUTPUT_PATH = f"magentic_one/logs/level_{LEVEL}_{on}_subset.json"
    else:
        OUTPUT_PATH = f"magentic_one/logs/level_{LEVEL}_{on}.json"
    
    # åŠ è½½ä»»åŠ¡
    tasks = load_tasks(
        on=on, 
        level=LEVEL,
        randomize=args.randomize,
        subset=args.subset_size,
        use_subset=args.use_subset,
        subset_file=args.subset_file
    )
    
    print(f"ğŸ“‹ åŠ è½½äº† {len(tasks)} ä¸ªä»»åŠ¡")
    if len(tasks) > 0:
        print(f"ğŸ” ç¬¬ä¸€ä¸ªä»»åŠ¡ID: {tasks[0]['task_id']}")

    # === æ–­ç‚¹é‡ç»­é€»è¾‘ä¿æŒä¸å˜ ===
    import os
    if os.path.exists(OUTPUT_PATH):
        with open(OUTPUT_PATH, "r", encoding="utf-8") as f:
            all_logs = json.load(f)
    else:
        all_logs = {}

    # === ä¿®æ”¹ï¼šæ¯ä¸ªä»»åŠ¡åˆ›å»ºæ–°çš„å›¢é˜Ÿï¼Œæ¯ä¸ª agent ä½¿ç”¨ç‹¬ç«‹çš„ model client ===
    for task in tasks:
        task_id = task["task_id"]
        if task_id in all_logs:
            print(f"Task {task_id} å·²å®Œæˆï¼Œè·³è¿‡ã€‚")
            continue
            
        # ä¸ºæ¯ä¸ª agent åˆ›å»ºç‹¬ç«‹çš„ model client
        surfer_client = create_model_client()
        file_surfer_client = create_model_client()
        coder_client = create_model_client()
        team_client = create_model_client()
        
        # ä¸ºæ¯ä¸ªä»»åŠ¡åˆ›å»ºæ–°çš„å›¢é˜Ÿå®ä¾‹ï¼Œä½¿ç”¨ç‹¬ç«‹çš„ clients
        surfer = MultimodalWebSurfer("WebSurfer", model_client=surfer_client)
        file_surfer = FileSurfer("FileSurfer", model_client=file_surfer_client)
        coder = MagenticOneCoderAgent("Coder", model_client=coder_client)
        terminal = CodeExecutorAgent("ComputerTerminal", code_executor=LocalCommandLineCodeExecutor())
        team = MagenticOneGroupChat([surfer, file_surfer, coder, terminal], model_client=team_client)

        question = task["Question"]
        answer = task["Final answer"]
        all_logs[task_id] = {}
        all_logs[task_id]["question"] = question
        all_logs[task_id]["correct_answer"] = answer
        all_logs[task_id]["logs"] = await run_task_and_capture_log(team, question)

        # æ¯åšå®Œä¸€ä¸ªå°±ä¿å­˜ä¸€æ¬¡
        os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)
        with open(OUTPUT_PATH, "w", encoding="utf-8") as f:
            json.dump(all_logs, f, ensure_ascii=False, indent=2)
        
        print(f"Task {task_id} å®Œæˆ")

    print(f"å…¨éƒ¨ä»»åŠ¡å¤„ç†å®Œæˆï¼Œæ—¥å¿—å·²ä¿å­˜åˆ° {OUTPUT_PATH}")

if __name__ == "__main__":
    asyncio.run(main())